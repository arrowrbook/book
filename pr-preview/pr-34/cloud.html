<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nic Crane, Jonathan Keane, and Neal Richardson">

<title>6&nbsp; Cloud – Scaling Up With R and Arrow</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./advanced_topics.html" rel="next">
<link href="./datasets.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./cloud.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Cloud</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Scaling Up With R and Arrow</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./foreword.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foreword</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./getting_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Getting Started</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data_manipulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Manipulation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./files_and_formats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Files and Formats</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cloud.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Cloud</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./advanced_topics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Advanced Topics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sharing Data and Interoperability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Appendix</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#working-with-data-in-cloud-storage" id="toc-working-with-data-in-cloud-storage" class="nav-link active" data-scroll-target="#working-with-data-in-cloud-storage"><span class="header-section-number">6.1</span> Working with data in cloud storage</a></li>
  <li><a href="#working-efficiently-with-cloud-data" id="toc-working-efficiently-with-cloud-data" class="nav-link" data-scroll-target="#working-efficiently-with-cloud-data"><span class="header-section-number">6.2</span> Working efficiently with cloud data</a>
  <ul class="collapse">
  <li><a href="#minimizing-data-transfer" id="toc-minimizing-data-transfer" class="nav-link" data-scroll-target="#minimizing-data-transfer"><span class="header-section-number">6.2.1</span> Minimizing data transfer</a></li>
  <li><a href="#network-location-and-transfer-speed" id="toc-network-location-and-transfer-speed" class="nav-link" data-scroll-target="#network-location-and-transfer-speed"><span class="header-section-number">6.2.2</span> Network location and transfer speed</a></li>
  </ul></li>
  <li><a href="#working-directly-with-a-bucket-object" id="toc-working-directly-with-a-bucket-object" class="nav-link" data-scroll-target="#working-directly-with-a-bucket-object"><span class="header-section-number">6.3</span> Working directly with a bucket object</a></li>
  <li><a href="#authentication" id="toc-authentication" class="nav-link" data-scroll-target="#authentication"><span class="header-section-number">6.4</span> Authentication</a>
  <ul class="collapse">
  <li><a href="#anonmyous" id="toc-anonmyous" class="nav-link" data-scroll-target="#anonmyous"><span class="header-section-number">6.4.1</span> Anonmyous</a></li>
  <li><a href="#manually-pass-in-credentials" id="toc-manually-pass-in-credentials" class="nav-link" data-scroll-target="#manually-pass-in-credentials"><span class="header-section-number">6.4.2</span> Manually pass in credentials</a></li>
  <li><a href="#a-credentials-file" id="toc-a-credentials-file" class="nav-link" data-scroll-target="#a-credentials-file"><span class="header-section-number">6.4.3</span> A credentials file</a></li>
  <li><a href="#environment-variables" id="toc-environment-variables" class="nav-link" data-scroll-target="#environment-variables"><span class="header-section-number">6.4.4</span> Environment variables</a></li>
  </ul></li>
  <li><a href="#configuring-bucket-region" id="toc-configuring-bucket-region" class="nav-link" data-scroll-target="#configuring-bucket-region"><span class="header-section-number">6.5</span> Configuring bucket region</a></li>
  <li><a href="#enabling-logging-in-s3" id="toc-enabling-logging-in-s3" class="nav-link" data-scroll-target="#enabling-logging-in-s3"><span class="header-section-number">6.6</span> Enabling Logging in S3</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">6.7</span> Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-cloud" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Cloud</span></span></h1>
<p class="subtitle lead">Bigger Data, Easier Workflows</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Nic Crane, Jonathan Keane, and Neal Richardson </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<p>In the previous chapters, we’ve discussed working with data which is stored on a local filesystem, but Arrow also can also work with data stored on a remote machine.</p>
<p>If you want to read a single file directly into memory, you can pass a URL directly into a file-reading function, and the file will be downloaded to a temporary directory and then loaded into your R session.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">read_parquet</span>(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"https://github.com/apache/arrow/raw/main/r/inst/v0.7.1.parquet"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["carat"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["cut"],"name":[2],"type":["chr"],"align":["left"]},{"label":["color"],"name":[3],"type":["chr"],"align":["left"]},{"label":["clarity"],"name":[4],"type":["chr"],"align":["left"]},{"label":["depth"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["table"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["price"],"name":[7],"type":["int"],"align":["right"]},{"label":["x"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["y"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["z"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["__index_level_0__"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.23","2":"Ideal","3":"E","4":"SI2","5":"61.5","6":"55","7":"326","8":"3.95","9":"3.98","10":"2.43","11":"0"},{"1":"0.21","2":"Premium","3":"E","4":"SI1","5":"59.8","6":"61","7":"326","8":"3.89","9":"3.84","10":"2.31","11":"1"},{"1":"0.23","2":"Good","3":"E","4":"VS1","5":"56.9","6":"65","7":"327","8":"4.05","9":"4.07","10":"2.31","11":"2"},{"1":"0.29","2":"Premium","3":"I","4":"VS2","5":"62.4","6":"58","7":"334","8":"4.20","9":"4.23","10":"2.63","11":"3"},{"1":"0.31","2":"Good","3":"J","4":"SI2","5":"63.3","6":"58","7":"335","8":"4.34","9":"4.35","10":"2.75","11":"4"},{"1":"0.24","2":"Very Good","3":"J","4":"VVS2","5":"62.8","6":"57","7":"336","8":"3.94","9":"3.96","10":"2.48","11":"5"},{"1":"0.24","2":"Very Good","3":"I","4":"VVS1","5":"62.3","6":"57","7":"336","8":"3.95","9":"3.98","10":"2.47","11":"6"},{"1":"0.26","2":"Very Good","3":"H","4":"SI1","5":"61.9","6":"55","7":"337","8":"4.07","9":"4.11","10":"2.53","11":"7"},{"1":"0.22","2":"Fair","3":"E","4":"VS2","5":"65.1","6":"61","7":"337","8":"3.87","9":"3.78","10":"2.49","11":"8"},{"1":"0.23","2":"Very Good","3":"H","4":"VS1","5":"59.4","6":"61","7":"338","8":"4.00","9":"4.05","10":"2.39","11":"9"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>If you want to work with multi-file datasets, however, the HTTP protocol isn’t compatible with Arrow’s ability to scan files and read metadata before data is accessed to optimize what is eventually pulled into memory upon collecting a query. Working with multi-file datasets is possible though when accessing remote data kept in cloud storage services such as Amazon Simple Storage Service (S3) and Google Cloud Storage (GCS).</p>
<p>There are different reasons that you might be working with cloud data, for example:</p>
<ul>
<li>datasets which are too large to be stored on a local machine</li>
<li>datasets being accessed as part of a process rather than interactively, e.g.&nbsp;data for a Shiny app deployed online</li>
<li>datasets which belong to someone else that you have been granted access to or using open data hosted on cloud filesystems</li>
</ul>
<p>In these circumstances, storing data in the cloud can offer multiple benefits:</p>
<ul>
<li>infrastructure can be scaled easily as the data grows</li>
<li>using a managed environment can increase reliability and uptime, and lower the need for maintenance</li>
<li>access can be provided to people in different locations easily</li>
</ul>
<p>However, there are some challenges which come with this, in terms of data storage and retrieval costs, as well as the potential for slow transfer times, which becomes increasing likely with larger workloads.</p>
<p>If the data is static (i.e.&nbsp;not being updated) and of a reasonable size to store on disk, then a relatively simple workflow would be to download the entire dataset and run calculations on it locally. This isn’t always feasible if the dataset is too large or if the data transfer time would negatively impact performance, and so an alternative is needed.</p>
<p>Fortunately, Arrow can help. Since storing data in Parquet format uses much less space than the equivalent CSV file, using Arrow can reduce both data storage and transfer costs. On top of that, transfer costs can also be further reduced by taking advantage of Arrow’s use of partitioning, only transferring the minimum data required from cloud storage to complete the query.</p>
<p>In this chapter, we’ll take a look at how to work with data which is hosted on cloud platforms, outline some platform-specific considerations, and show you how to work the most efficiently with cloud data.</p>
<p>While we focus on Parquet datasets, the techniques shown here can be used on CSV datasets. CSVs work fine, but they’re slower and more expensive. While you can work with compressed CVSs, this solves part of the problem, but not all of it<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>Many examples will look at working with data hosted on Amazon S3, but the same principles can also be used with data in GCS. There are some subtle differences between S3 and GCS which we’ll highlight when they come up and outline any differences you need to be aware of. In the future, the Apache Arrow project plans to add functionality to work with additional cloud storage services like Azure Blob Storage—this implementation and future ones relating to any other cloud storage services will also follow this model.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>In cloud storage terminology, S3 and GCS refer to the place where the data is stored as a <strong>bucket</strong>. Other systems may use alternative terms, like “blob”, but we will use “bucket” here as a generic term.</p>
<section id="working-with-data-in-cloud-storage" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="working-with-data-in-cloud-storage"><span class="header-section-number">6.1</span> Working with data in cloud storage</h2>
<p>Working with cloud storage services is similar in many ways to working with data stored in local filesystems, and you can use the same file and dataset opening functions for both tasks. To open a file or dataset saved in cloud storage, instead of passing in a path to a local file to these functions, you can instead pass in the cloud storage path as a URI.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">read_parquet</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste0</span>(<span class="st">"s3://scaling-arrow-pums/person/year=2005/"</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>         <span class="st">"location=ak/part-0.parquet"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">open_dataset</span>(<span class="st">"s3://scaling-arrow-pums/person/"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that when working with data stored on GCS, even when working with a publicly accessible bucket, you’ll need to provide a login name of “anonymous”. The equivalent of the above commands for GCS—these won’t run here as these buckets haven’t been set up—would be:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">read_parquet</span>(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste0</span>(<span class="st">"gs://anonymous@scaling-arrow-pums/person/year=2005/"</span>,</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>         <span class="st">"location=ak/part-0.parquet"</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">open_dataset</span>(<span class="st">"gs://anonymous@scaling-arrow-pums/person/"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s take a closer look at running queries in the cloud. If we create a new dataset connecting to the S3 bucket and take a look at the object, we’ll see it looks the same as a local dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>person_data <span class="ot">&lt;-</span> <span class="fu">open_dataset</span>(<span class="st">"s3://scaling-arrow-pums/person/"</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>person_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>FileSystemDataset with 884 Parquet files
311 columns
SPORDER: int32
RT: dictionary&lt;values=string, indices=int32&gt;
SERIALNO: string
PUMA: string
ST: string
ADJUST: int32
PWGTP: int32
AGEP: int32
CIT: dictionary&lt;values=string, indices=int32&gt;
COW: dictionary&lt;values=string, indices=int32&gt;
DDRS: bool
DEYE: bool
DOUT: bool
DPHY: bool
DREM: bool
DWRK: bool
ENG: dictionary&lt;values=string, indices=int32&gt;
FER: bool
GCL: bool
GCM: dictionary&lt;values=string, indices=int32&gt;
...
291 more columns
Use `schema()` to see entire schema</code></pre>
<p>The key difference here is that we know that the data is stored on the cloud. One of the advantages of working with arrow when dealing with cloud datasets is that we can take advantage of both partitioning and lazy evaluation—we can construct the query that we’re going to run on our dataset without pulling anything into memory or transferring the data from cloud storage to our local machine.</p>
<p>Let’s write a query which will calculate the highest age recorded in the dataset for the state of California in 2022.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>max_age_ca_2022 <span class="ot">&lt;-</span> person_data <span class="sc">|&gt;</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">2022</span>, location <span class="sc">==</span> <span class="st">"ca"</span>) <span class="sc">|&gt;</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">max_age =</span> <span class="fu">max</span>(AGEP))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>max_age_ca_2022</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>FileSystemDataset (query)
max_age: int32

See $.data for the source Arrow object</code></pre>
<p>Again, it looks just like the same query would when set up to run on a local copy of the data. Now when we call <code>collect()</code> to pull the data into our R session, we will only download a subset of the data necessary to run our query.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect</span>(max_age_ca_2022)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["max_age"],"name":[1],"type":["int"],"align":["right"]}],"data":[{"1":"94"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>An important question to ask here is how long it took to run the query. We compared running the same query from above on the same machine—a Posit Cloud instance with 1GB of RAM—with a local copy of the data compared to the cloud version of the same data. The results are shown in <a href="#tbl-cloud-local" class="quarto-xref">Table&nbsp;<span>6.1</span></a>.</p>
<div id="tbl-cloud-local" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-cloud-local-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6.1: Time taken to run the same query on a local machine and connecting to an S3 bucket
</figcaption>
<div aria-describedby="tbl-cloud-local-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Location</th>
<th>Time (s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Local</td>
<td>0.2</td>
</tr>
<tr class="even">
<td>Cloud</td>
<td>24.1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>There’s a huge difference between these results: it was 120 times faster to work with a local copy of the data! This was due to the need for data transfer; in the local query, Arrow could just scan the data and perform the necessary calculations, whereas in the cloud query, we needed to download the data first before we could return it to our R session.</p>
<p>A reasonable question to ask here might be why did it took 24 seconds to run a query which only had 1 row of data in the results? The answer to this question is that we actually downloaded more than 1 row of data—in fact, we downloaded all of the data for California in 2022—with the final aggregation being performed locally. Let’s take a look at the reasons for this, and see what we can do to minimize data transfer in our queries.</p>
</section>
<section id="working-efficiently-with-cloud-data" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="working-efficiently-with-cloud-data"><span class="header-section-number">6.2</span> Working efficiently with cloud data</h2>
<p>Pulling data from cloud storage can be slow—the main bottleneck is transferring data over the internet—and it takes longer than querying data locally. Given that increased data transfer results in increased costs and slower retrieval of results, it’s important to understand how to minimize the amount of data that needs to be downloaded.</p>
<section id="minimizing-data-transfer" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="minimizing-data-transfer"><span class="header-section-number">6.2.1</span> Minimizing data transfer</h3>
<p>In this section, we’ll look at how we can run queries on the cloud datasets but only download a relevant subset of the data, and discuss different strategies for minimizing data transfer when working with data in cloud storage.</p>
<p>Tools for measuring data transfer vary between different operating systems; in the code examples below, we’ll show the output from a Linux tool called <a href="https://github.com/raboof/nethogs">nethogs</a>. If you want to test out data transfer yourself, see <a href="appendix.html#sec-netmon" class="quarto-xref">Section&nbsp;<span>A.3.1</span></a> for more information about the commands we ran to measure bandwidth.</p>
<section id="partitioning" class="level4" data-number="6.2.1.1">
<h4 data-number="6.2.1.1" class="anchored" data-anchor-id="partitioning"><span class="header-section-number">6.2.1.1</span> Partitioning</h4>
<p>We introduced strategies for efficient partitioning when working with datasets in <a href="datasets.html" class="quarto-xref">Chapter&nbsp;<span>5</span></a>, but this becomes even more important when working with data in cloud storage.</p>
<p>The full copy of the PUMS person dataset is just under 8GB of Parquet files. Let’s say we want to collect a subset of the PUMS person dataset, filtering to include only data from respondents in California in 2022. Let’s take a look at our local copy to see how many rows of data this is.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">open_dataset</span>(<span class="st">"./data/person"</span>) <span class="sc">|&gt;</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">2022</span>, location <span class="sc">==</span> <span class="st">"ca"</span>) <span class="sc">|&gt;</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nrow</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 391171</code></pre>
<p>The resulting dataset contains just under 400,000 rows of data, which takes up just under 60MB on disk.</p>
<p>The crucial question we want to ask next is: how much data is transferred to our local machine when run the same query on the dataset stored in S3 and then retrieve the results? Let’s run the code to get the data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>ca_2022 <span class="ot">&lt;-</span> <span class="fu">open_dataset</span>(<span class="st">"s3://scaling-arrow-pums/person"</span>) <span class="sc">|&gt;</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">2022</span>, location <span class="sc">==</span> <span class="st">"ca"</span>) <span class="sc">|&gt;</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Running that query downloaded 61.8MB of data, closely matching the amount of space that the Parquet files in the dataset take up on disk. It’s slightly higher by a couple of megabytes, but this is due to other transfer overhead, such as connecting to the S3 bucket itself and reading the file headers.</p>
<p>Now, what if we want to filter to only return data for individuals who are the maximum age we found earlier— 94? Let’s count the rows of data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">open_dataset</span>(<span class="st">"s3://scaling-arrow-pums/person"</span>) <span class="sc">|&gt;</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">2022</span>, location <span class="sc">==</span> <span class="st">"ca"</span>, AGEP <span class="sc">==</span> <span class="dv">94</span>) <span class="sc">|&gt;</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nrow</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 3111</code></pre>
<p>This is a much smaller subset—around 3,000 rows of data compared to 400,000. So how much data is transferred when we run this on S3?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>ca_2022_94 <span class="ot">&lt;-</span> <span class="fu">open_dataset</span>(<span class="st">"s3://scaling-arrow-pums/person"</span>) <span class="sc">|&gt;</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">2022</span>, location <span class="sc">==</span> <span class="st">"ca"</span>, AGEP <span class="sc">==</span> <span class="dv">94</span>) <span class="sc">|&gt;</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The amount of data transferred was 61.8MB, exactly the same as last time—so what’s going on here?</p>
<p>Arrow is able to use the partition variables <code>year</code> and <code>location</code> to work out which files contain the data needed, in both examples. In the second example, arrow needs access to the values in the files to be able to filter by <code>AGEP</code> and so all values in the files have to be transferred first. In this dataset, there is one file per unique combination of <code>year</code> and <code>location</code> and so we know the data we need must be in a single file. If the data is split across multiple files, arrow can make use of the Parquet file metadata—more on that later—to work out whether that file needs downloading.</p>
<p>This shows the need for careful thought when deciding how to partition your data that you’ll be keeping in cloud storage—you can reduce transfer costs significantly by partitioning data on columns which are more commonly used in filters. This must, however, be balanced with not creating too many partitions, otherwise transfers may be slowed down significantly by the need to access large numbers of individual files.</p>
<p>As with the examples we discussed in <a href="datasets.html" class="quarto-xref">Chapter&nbsp;<span>5</span></a>, when deciding how to partition your data, experimentation can help in working out how to strike the right balance.</p>
<p>While partitioning can help reduce the total amount of data transferred when working with any arrow-compatible formats in cloud storage, working specifically with Parquet files brings some additional advantages, which we’ll take a look at in the next section.</p>
</section>
<section id="parquet-statistics" class="level4" data-number="6.2.1.2">
<h4 data-number="6.2.1.2" class="anchored" data-anchor-id="parquet-statistics"><span class="header-section-number">6.2.1.2</span> Parquet statistics</h4>
<p>Another way in which arrow can limit the amount of data transferred over the network is taking advantage of statistics stored in Parquet metadata.</p>
<p>Let’s say we wanted to take the entire dataset and retrieve a subset which only includes people aged 97 or older, across all years and locations. We can run the following query.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">open_dataset</span>(<span class="st">"s3://scaling-arrow-pums/person/"</span>) <span class="sc">|&gt;</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(AGEP <span class="sc">&gt;=</span> <span class="dv">97</span>) <span class="sc">|&gt;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_dataset</span>(<span class="st">"./data/transient_data/olds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The resulting file was 228KB in total, with 110 MB of data transferred even though the query itself is not limited to our specific partitioning columns: <code>year</code> or <code>location</code>.</p>
<p>So how is it possible that we only downloaded a subset of the full dataset despite filtering on a non-partitioning column? And why did it require 110MB of data to be transferred?</p>
<p>Parquet metadata contains information about minimum and maximum values in each of the columns in each file. This means that arrow can inspect this metadata and only return data from files which might contain relevant values, filtering this data further locally once it’s been downloaded from cloud storage.</p>
<p>If we take a look at our local copy of the data, we can apply the same filter, extract the names of the files from which the filtered rows appear in, and then look at their total size.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">open_dataset</span>(<span class="st">"data/person/"</span>) <span class="sc">|&gt;</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(AGEP <span class="sc">&gt;=</span> <span class="dv">97</span>) <span class="sc">|&gt;</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">transmute</span>(<span class="at">filename =</span> <span class="fu">add_filename</span>()) <span class="sc">|&gt;</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>() <span class="sc">|&gt;</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(<span class="at">as_vector =</span> <span class="cn">TRUE</span>) <span class="sc">|&gt;</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map_int</span>(fs<span class="sc">::</span>file_size) <span class="sc">|&gt;</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>() <span class="sc">|&gt;</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  fs<span class="sc">::</span><span class="fu">as_fs_bytes</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>4.88M</code></pre>
</div>
</div>
<p>This is still way less than the 110MB of data transferred, so how do we account for the additional 105MB?</p>
<p>The problem here is that we haven’t accounted for the data transferred when arrow reads the file headers so it can use the statistics to work out whether the file contains relevant data to filter further locally.</p>
<p>To find out how much data is transferred to inspect the headers, we can take a baseline measure that looks at how much data is transferred if we run a query that results in 0 rows of data being saved to disk. We can filter the dataset to only include respondents with an age greater than 1097 years.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">open_dataset</span>(<span class="st">"s3://scaling-arrow-pums/person/"</span>) <span class="sc">|&gt;</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(AGEP <span class="sc">&gt;=</span> <span class="dv">1097</span>) <span class="sc">|&gt;</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_dataset</span>(<span class="st">"./data/transient_data/ancients"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nothing was written to disk as the resulting dataset contained 0 rows, but 105MB of data was transferred. Those 105MB of data are our Parquet file headers; when we add that to the total sizes of the files containing relevant data, 5MB, we get the total amount of data transferred: 110MB.</p>
<p>The same principle can also be applied to missing values If your data has a lot of missing values, Parquet statistics contain metadata about how many values in each column are missing, so arrow can skip transferring files when there is no data present in a column.</p>
</section>
</section>
<section id="network-location-and-transfer-speed" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="network-location-and-transfer-speed"><span class="header-section-number">6.2.2</span> Network location and transfer speed</h3>
<p>Another consideration when working with cloud data like this is the relative geographic locations of where the data is stored, and the location of the computer which is accessing the data.</p>
<section id="selecting-a-bucket-region" class="level4" data-number="6.2.2.1">
<h4 data-number="6.2.2.1" class="anchored" data-anchor-id="selecting-a-bucket-region"><span class="header-section-number">6.2.2.1</span> Selecting a bucket region</h4>
<p>If you’re setting up a new cloud storage bucket, you’ll see faster performance when querying data if you choose a region which is geographically close to the machines from which individual users or apps will be accessing the data from, and even faster performance when within the same network.</p>
<p>To demonstrate this, we took a look at the speed of running a query which returned the data for California in 2022.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>tf <span class="ot">&lt;-</span> <span class="fu">tempfile</span>()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dir.create</span>(tf)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">open_dataset</span>(<span class="st">"s3://scaling-arrow-pums/person"</span>) <span class="sc">|&gt;</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(year <span class="sc">==</span> <span class="dv">2022</span>, location <span class="sc">==</span> <span class="st">"ca"</span>) <span class="sc">|&gt;</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">write_dataset</span>(tf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The resulting file was a 60MB Parquet file.</p>
<p>We ran this query on Nic’s laptop connecting to the following buckets:</p>
<ol type="1">
<li>the original S3 bucket located in <code>us-east-1</code> region</li>
<li>an identical bucket located in the <code>eu-west-2</code> region, in London</li>
</ol>
<p>We then tried the queried the original S3 bucket again, but from a Posit Cloud instance deployed on Amazon EC2 in the <code>us-east-1</code> region.</p>
<p>The average times across 3 runs are shown in <a href="#tbl-cloud-location" class="quarto-xref">Table&nbsp;<span>6.2</span></a>.</p>
<div id="tbl-cloud-location" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-cloud-location-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6.2: Time taken to run the same query with varying bucket location and access location
</figcaption>
<div aria-describedby="tbl-cloud-location-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Bucket Location</th>
<th>Access Location</th>
<th>Time (seconds)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Virginia, US (us-east-1)</td>
<td>Manchester, UK</td>
<td>56</td>
</tr>
<tr class="even">
<td>London, UK (eu-west-2)</td>
<td>Manchester, UK</td>
<td>50</td>
</tr>
<tr class="odd">
<td>Virginia, US (us-east-1)</td>
<td>Virginia, US (us-east-1)</td>
<td>24</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Using a bucket in the same geographical region resulted in a slight decrease in time to run the query and collect the data, when transferring the results to work with locally. However, geographic location alone wasn’t the sole factor determining transfer times.</p>
<p>The time to complete the query was significantly shorter on Posit Cloud deployed on EC2 than when transferring to a machine outside of the AWS network. The speed up is because of the interconnection between AWS data centers as well as the fact that the data is now being transferred within AWS’s internal network with optimized infrastructure, rather than over the internet.</p>
<p>It’s also worth keeping in mind the impact on cost—not just in terms of speed, but money too. At time of writing, it was free to transfer data from an S3 bucket to another AWS service like EC2 within the same AWS region, but there were charges associated with transferring data between regions, or out to the internet, which was the most expensive of all.</p>
</section>
</section>
</section>
<section id="working-directly-with-a-bucket-object" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="working-directly-with-a-bucket-object"><span class="header-section-number">6.3</span> Working directly with a bucket object</h2>
<p>The previous examples in this chapter all involved working with datasets by passing in a URI. This is the simplest path to working with data in cloud storage, though you might need a finer degree of control to go beyond the default configuration. In such cases, you can work directly with a bucket object.</p>
<p>You can create an object representing the connection to the bucket itself, which can then be manipulated further, allowing the possibility of passing in additional parameters, such as those relating to authentication.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>bucket <span class="ot">&lt;-</span> <span class="fu">s3_bucket</span>(<span class="st">"scaling-arrow-pums"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we’re connected to the bucket, let’s take a look around. We can use the <code>ls()</code> method to list all the directories inside the bucket.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>bucket<span class="sc">$</span><span class="fu">ls</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] "household"   "person"      "raw_csvs"    "readme.html"</code></pre>
<p>If we want to look further into an individual directory, we can pass in the name of the directory to <code>ls()</code> to take a look inside. Let’s check out the contents of the <code>person</code> directory.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>bucket<span class="sc">$</span><span class="fu">ls</span>(<span class="st">"person"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code> [1] "person/year=2005" "person/year=2006" "person/year=2007" "person/year=2008" "person/year=2009" "person/year=2010" "person/year=2011"
 [8] "person/year=2012" "person/year=2013" "person/year=2014" "person/year=2015" "person/year=2016" "person/year=2017" "person/year=2018"
[15] "person/year=2019" "person/year=2021" "person/year=2022"</code></pre>
<p>If we want to work just with the data in this directory, we can use the <code>path()</code> method to create a new object that points just to this directory, e.g.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>person_bucket <span class="ot">&lt;-</span> bucket<span class="sc">$</span><span class="fu">path</span>(<span class="st">"person"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And what if we want to list all of the files inside our bucket? We can pass the argument <code>recursive = TRUE</code> to the <code>ls()</code> method. Let’s take a look at the first 10 elements of the contents of the 2022 directory.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>person_2022_data <span class="ot">&lt;-</span> person_bucket<span class="sc">$</span><span class="fu">path</span>(<span class="st">"year=2022"</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(person_2022_data<span class="sc">$</span><span class="fu">ls</span>(<span class="at">recursive =</span> <span class="cn">TRUE</span>), <span class="at">n =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code> [1] "location=ak/part-0.parquet" "location=ak"                "location=al/part-0.parquet" "location=al"
 [5] "location=ar/part-0.parquet" "location=ar"                "location=az/part-0.parquet" "location=az"
 [9] "location=ca/part-0.parquet" "location=ca"</code></pre>
<p>Just as if we wanted to list all of the files in the local copy by calling <code>fs::dir_ls("./data/person/year=2022)</code>, we can see that the call to the <code>ls()</code> method above lists both the directories and files stored inside of them. In S3, this is the default, but if working with GCS, you must pass in the argument <code>recursive = TRUE</code> to get all of the files and directories.</p>
<p>Now we’ve connected to the bucket, how do we actually work with the data? As mentioned earlier in this chapter, the simplest way, if you have a single file which you want to read entirely into memory is using the same <code>read_*</code> functions you’d use to work with a local file, passing in the path to the file or dataset on cloud storage.</p>
<p>If you’ve created a bucket object, this can also be passed into <code>read_parquet()</code> and other file-reading functions or <code>open_dataset()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>person_data <span class="ot">&lt;-</span> <span class="fu">open_dataset</span>(person_bucket)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The examples we’ve looked at so far have all been on a bucket that hasn’t required us to provide any login details, but what about if we want to connect to a bucket which requires us to provide credentials? We’ll take a look at that in the next section.</p>
</section>
<section id="authentication" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="authentication"><span class="header-section-number">6.4</span> Authentication</h2>
<p>There are multiple options for how provide credential when connecting to S3 or GCS, and these methods of authentication vary between providers.</p>
<p>In this section, we’re going to talk about:</p>
<ul>
<li>anonymous login</li>
<li>passing credentials in manually</li>
<li>using a credentials files</li>
<li>using environment variables</li>
</ul>
<p>Different methods of authentication are more suitable for different circumstances. In short:</p>
<ul>
<li>anonymous login is fine for accessing publicly-accessible buckets but won’t work for private buckets where you need to supply credentials</li>
<li>the simplest method is to pass in your credentials manually as parameters, but it is also the least secure</li>
<li>passing in credentials via an environment variable is great for when you are using a script and don’t want the details hard-coded where other people can see them</li>
<li>using a credentials file removes the need to manually pass in credentials once it’s been configured</li>
</ul>
<p>If you already have been working with cloud storage services via another program or the command line, you might already have one of these options configured. It’s important to only use one method to prevent confusion if the values are in conflict.</p>
<p>There are other possible methods, which you can find more information about in the <a href="https://docs.aws.amazon.com/sdk-for-cpp/v1/developer-guide/credentials.html">AWS docs</a> or the <a href="https://cloud.google.com/docs/authentication">GCS docs</a>. We’ve included some examples of the most common methods below. At the time of writing these are how the methods work, but this might change. As always, look to the relevant docs for the most up-to-date methods and best practices.</p>
<p>Generally, we recommend using a credentials file when working locally, but environment variables when working with applications deployed online.</p>
<p>In the next section, we’ll walk through the different options.</p>
<section id="anonmyous" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="anonmyous"><span class="header-section-number">6.4.1</span> Anonmyous</h3>
<p>If you’re connecting to a publicly accessible bucket, you can log in anonymously, but how you do this differs between S3 and AWS.</p>
<section id="s3" class="level4" data-number="6.4.1.1">
<h4 data-number="6.4.1.1" class="anchored" data-anchor-id="s3"><span class="header-section-number">6.4.1.1</span> S3</h4>
<p>If you’re connecting to a public S3 bucket, you don’t need to pass in any credentials.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>bucket <span class="ot">&lt;-</span> <span class="fu">s3_bucket</span>(<span class="st">"scaling-arrow-pums"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>However, if you already have AWS credentials configured via another method, such as a credentials file, you should pass in the <code>anonymous = TRUE</code> argument to prevent those credentials being automatically detected and used, otherwise access may fail.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>bucket <span class="ot">&lt;-</span> <span class="fu">s3_bucket</span>(<span class="st">"scaling-arrow-pums"</span>, <span class="at">anonymous =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="gcs" class="level4" data-number="6.4.1.2">
<h4 data-number="6.4.1.2" class="anchored" data-anchor-id="gcs"><span class="header-section-number">6.4.1.2</span> GCS</h4>
<p>In GCS, different host names are used depending on whether the user is logged in or not. This means that if you want to connect to a GCS instance without providing authentication credentials, you must manually set <code>anonymous</code> to <code>TRUE</code> to make sure that the correct host name is used.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>bucket <span class="ot">&lt;-</span> <span class="fu">gs_bucket</span>(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"scaling-arrow-pums/person/"</span>,</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">anonymous =</span> <span class="cn">TRUE</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="manually-pass-in-credentials" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="manually-pass-in-credentials"><span class="header-section-number">6.4.2</span> Manually pass in credentials</h3>
<p>The simplest way to connect to a private bucket is to pass in credentials manually. These methods are fine for working with code interactively, but run the risk of accidentally being checked into version control and exposing these details to others. This isn’t arrow-specific advice, but rather, is general best practice. Putting secrets in your code means they’re in your command history, as well as possibly checked into source control and exposed.</p>
<section id="s3-1" class="level4" data-number="6.4.2.1">
<h4 data-number="6.4.2.1" class="anchored" data-anchor-id="s3-1"><span class="header-section-number">6.4.2.1</span> S3</h4>
<p>In AWS S3, this is done using your login, <code>access_key</code> and password, <code>secret_key</code> into <code>s3_bucket()</code> when creating a new connection.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>secret_data <span class="ot">&lt;-</span> <span class="fu">s3_bucket</span>(</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"secret_bucket_name"</span>,</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">access_key =</span> <span class="st">"nic"</span>,</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">secret_key =</span> <span class="st">"12345"</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Similarly, you can pass all of these details in as a single URI string.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>secret_data <span class="ot">&lt;-</span> <span class="fu">s3_bucket</span>(<span class="st">"s3://nic:12345@secret_bucket_name"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="gcs-1" class="level4" data-number="6.4.2.2">
<h4 data-number="6.4.2.2" class="anchored" data-anchor-id="gcs-1"><span class="header-section-number">6.4.2.2</span> GCS</h4>
<p>In GCS, you’ll need to get an access token and its expiration date, which you can then pass into the call to <code>gs_bucket()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>secret_data <span class="ot">&lt;-</span> <span class="fu">gs_bucket</span>(</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"secret_bucket_name"</span>,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">access_token =</span> <span class="st">"ab12.ABCS6ZRVmB7fkLtd1XTmq6mo0s-6Uw7p8vtgSwg"</span>,</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">expiration =</span> <span class="fu">as.POSIXct</span>(<span class="st">"2024-08-09 12:00:00"</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="a-credentials-file" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3" class="anchored" data-anchor-id="a-credentials-file"><span class="header-section-number">6.4.3</span> A credentials file</h3>
<p>Credentials files can be a convenient way of configuring your authentication and other configuration without having to manually set multiple environment variables.</p>
<section id="s3-2" class="level4" data-number="6.4.3.1">
<h4 data-number="6.4.3.1" class="anchored" data-anchor-id="s3-2"><span class="header-section-number">6.4.3.1</span> S3</h4>
<p>AWS credentials files can be a convenient way of configuring your authentication and other configuration without having to manually set multiple environment variables. AWS credentials files are typically stored for Linux and macOS users at <code>~/.aws/credentials</code> or <code>C:\Users\&lt;username&gt;\.aws\credentials</code> for Windows users, though you can store them in another location and set the <code>AWS_SHARED_CREDENTIALS_FILE</code> environment variable to point to their location to ensure they are automatically detected.</p>
<p>When the AWS SDK is initialized, it will look for this credentials file automatically, so you don’t need to make any changes in your code in order to be able to use them.</p>
</section>
<section id="gcs-2" class="level4" data-number="6.4.3.2">
<h4 data-number="6.4.3.2" class="anchored" data-anchor-id="gcs-2"><span class="header-section-number">6.4.3.2</span> GCS</h4>
<p>If you need to provide credentials, and have the Google Cloud CLI installed, you can set up a local credentials file by setting up Application Default Credential (ADC) by running the following code from the command line:</p>
<pre><code>gcloud auth application-default login</code></pre>
</section>
</section>
<section id="environment-variables" class="level3" data-number="6.4.4">
<h3 data-number="6.4.4" class="anchored" data-anchor-id="environment-variables"><span class="header-section-number">6.4.4</span> Environment variables</h3>
<p>A more secure method of authentication when working with cloud storage in applications deployed on continuous integration (CI) systems like Github Actions is the use of environment variables. Using this method means that the credentials don’t appear in your code or console logs anywhere, and thus can be a useful of ensuring your credentials remain secure if you want to share your code with others. By setting the environment variables outside of your script, you can share your code without sharing your credentials.</p>
<section id="s3-3" class="level4" data-number="6.4.4.1">
<h4 data-number="6.4.4.1" class="anchored" data-anchor-id="s3-3"><span class="header-section-number">6.4.4.1</span> S3</h4>
<p>You can set the environment variables <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> to your access key and secret key, and the AWS SDK will automatically check if these variables have been set, and if they are, use the values in them to authenticate.</p>
</section>
<section id="gcs-3" class="level4" data-number="6.4.4.2">
<h4 data-number="6.4.4.2" class="anchored" data-anchor-id="gcs-3"><span class="header-section-number">6.4.4.2</span> GCS</h4>
<p>It’s a little different with GCS: if deploying an application to a CI/CD system such as GitHub Actions, the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable should be pointed to the location of the JSON credentials file. As it wouldn’t be secure to store this file in your repository, you’ll need to take an alternative approach such as encoding your service account key and storing this value as another environment variable, decoding it within the CI, and then setting the <code>GOOGLE_APPLICATION_CREDENTIALS</code> variable to this location. The details of how to do this are beyond the scope of this book, but check out the <a href="https://cloud.google.com/docs/authentication/provide-credentials-adc#local-key">Google Cloud documentation</a> for more information.</p>
</section>
</section>
</section>
<section id="configuring-bucket-region" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="configuring-bucket-region"><span class="header-section-number">6.5</span> Configuring bucket region</h2>
<p>If you don’t specify the region that the data is stored in, then Arrow will work it out based on your configuration and a few different heuristics.</p>
<p>Providing this manually will speed up the initial bucket connection, though won’t have an effect on subsequent analyses.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>bucket <span class="ot">&lt;-</span> <span class="fu">s3_bucket</span>(<span class="st">"scaling-arrow-pums"</span>, <span class="at">region =</span> <span class="st">"us-east-1"</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>bucket <span class="ot">&lt;-</span> <span class="fu">gs_bucket</span>(<span class="st">"scaling-arrow-pums"</span>, <span class="at">region =</span> <span class="st">"US-EAST1"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="enabling-logging-in-s3" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="enabling-logging-in-s3"><span class="header-section-number">6.6</span> Enabling Logging in S3</h2>
<p>When working specifically data stored in AWS S3, arrow provides an interface to official libraries supplied by AWS, which are capable of detailed logging. By default, the AWS logging level is set to <code>FATAL</code>, meaning only critical errors that cause the code to fail will be shown.</p>
<p>However, if things aren’t working as expected, you may want to select a different logging level to get a better idea of exactly what’s going on. You can do this by setting the <code>ARROW_S3_LOG_LEVEL</code> environment variable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="st">"ARROW_S3_LOG_LEVEL"</span> <span class="ot">=</span> <span class="st">"DEBUG"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To manually set the logging level, you need to do this before you use any S3-related functions. If you need to change it later, you’ll need to restart your R session first. This environment variable is read the first time during your R session that you use a function in arrow which uses the AWS SDK, initializing the SDK with settings which persist for the whole session.</p>
<p>The possible log levels, from least verbose to most verbose are: <code>"OFF"</code>, <code>"FATAL"</code> (the default), <code>"ERROR"</code>, <code>"WARN"</code>, <code>"INFO"</code>, <code>"DEBUG"</code>, and <code>"TRACE"</code>.</p>
<p>While the default logging level is usually sufficient, if you encounter issues like a slow connection or credentials not working, increasing the logging level can help you diagnose the problem.</p>
</section>
<section id="summary" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="summary"><span class="header-section-number">6.7</span> Summary</h2>
<p>In this chapter, we looked at working with data in cloud storage using arrow, including reading files from S3 and GCS, strategies for working efficiently with cloud data, including partitioning data effectively so that arrow can entirely skip scanning files which aren’t relevant to the current query. We also saw how working with Parquet files enables arrow to use metadata in file headers to decide whether to download an individual file or not when executing a query. Additionally, we highlighted the importance of considering where the data is being accessed from, and configuring regions to optimize performance and reduce data transfer times. Finally, we covered working with bucket objects, and authentication.</p>
<p>Generally, if you’re regularly analyzing data stored on S3 with arrow and looking to minimize data transfer costs, it’s worth experimenting with dataset configuration to find the most efficient setup for your particular analysis needs.</p>
<p>This chapter provided an overview of the key practical steps and considerations for integrating cloud storage into your data workflows using Arrow. For more advanced functionality and detailed options, refer to the documentation for the <a href="https://arrow.apache.org/docs/r/reference/FileSystem.html"><code>FileSystem</code></a> classes.</p>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>The lack of metadata with this format reduces the number of optimizations that Arrow can take advantage of. You can read more about working with compressed CSVs in <a href="files_and_formats.html#sec-writing-csvs" class="quarto-xref">Section&nbsp;<span>4.2.3</span></a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>At the time of writing, the Arrow C++ library has introduced support for Azure Blob Storage. Users of PyArrow can query datasets on Azure from Python, and once bindings are added to the arrow R package, it will be available from R.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./datasets.html" class="pagination-link" aria-label="Datasets">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Datasets</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./advanced_topics.html" class="pagination-link" aria-label="Advanced Topics">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Advanced Topics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>